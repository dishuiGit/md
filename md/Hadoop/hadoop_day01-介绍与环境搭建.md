[TOC]
##一、引出hadoop
###1、hadoop的高薪现状
给出几个招聘截图----> 高薪，职位所需求的技能
----> 引出好奇，hadoop是什么，为什么会这么高薪？引出大数据，大数据时代，大数据与云计算

###2、大数据时代的介绍
大数据的故事，google根据海量数据所作出的一次流行病传播趋势预测，及时性和准确性都远超医疗体系根据传统方法所作出的预警，渲染大数据技术将给这个时代带来的巨大变革 ----> 大数据的4V特征  ----> 大数据技术带来的更多成功案例，及基于大数据技术的机器学习带来的无限憧憬

###3、hadoop的由来和发展历程 
----> google所面临的困境 ----> 需求催生的技术革新 ----> 论文公布  ---->  dougcutting 山寨（捎带介绍一下道哥及其成就） ----> lucene nutch hadoop等项目的发起人 ----> yahoo ----> apache基金会管理维护
介绍apache基金会及其重要项目
介绍apache基金会旗下的hadoop生态体系中各种开源项目，入hive  hbase  flume  spark  storm  sqoop   oozie  ......（此处只是略带浏览一下，后面详细讲解hadoop生态系统）


###4、hadoop解决了什么问题
此处尽量通俗浅显地描述（先通过实际场景举例来引导：实际场景，海量日志如何处理，海量网页数据如何处理）
hdfs  解决了海量数据的分布式存储，高可靠，易扩展，高吞吐量
mapreduce   解决了海量数据的分析处理，通用性强，易开发，健壮性


###5、hadoop的发展现况
大数据领域的标准开源解决方案，各大主流厂商都围绕hadoop进行周边开发和服务提供，去IOE化
重点以淘宝为例： 集群用途，个数，规模，云梯的架构
顺带介绍中国移动所使用的hadoop集群及其用途
（笑料：各大厂商在使用hadoop，itcast也在使用hadoop）

###6、hadoop生态系统
分层次讲解
----> 最底层平台 hdfs   yarn  mapreduce  spark
---- > 应用层   hbase  hive pig  sparkSQL  nutch 
----> 工具类   zookeeper  flume 


##二、hadoop介绍

###1、解决问题：
海量数据的存储（HDFS）
海量数据的分析（MapReduce）
资源管理调度（YARN）


###2、版本
Apache
    官方版本(2.4.1)
Cloudera
	使用下载最多的版本，稳定，有商业支持，在Apache的基础上打上了一些patch。推荐使用。
HDP(Hortonworks Data Platform)
    Hortonworks公司发行版本。

###3、hadoop核心
HDFS: Hadoop Distributed File System 分布式文件系统 
YARN: Yet Another Resource Negotiator 
Mapreduce：分布式运算框架
###4、如何学习hadoop
学什么？分轻重缓急，首先是整体技术架构，然后是应用场景，然后是开发规范，有余力可以深入原理--如源码）
怎样学？注意比较跟学习J2EE的差别
难不难？给以信心，强调要多动手，因为hadoop领域技术点多，不像j2ee那么单纯，在动手的过程中会遇到各种各样的问题，这样一能加深理解，二能提高学习和思考分析的能力，三能积累问题解决经验

###5、hadoop的设计思想
```
单机性能纵向扩展的瓶颈，传统分布式存储入NFS所面临的单节点故障，磁盘冗余阵列所带来的成本问题
----> 需要通过集群协作来解决：水平扩展，集群化处理 ，低成本，可扩展，高可靠 
----> 集群协作随之而来的系统复杂度，急需一个通用的平台封装底层复杂度，降低使用开发难度

hdfs设计思想介绍 
	----主从结构， 主节点namenode，从节点datanode ，简单介绍其角色责任，节点数量
用仓库管理系统的比喻方式来介绍一遍hdfs的设计思想：
	---->管理员，仓库的角色
	---->可靠性的考虑
	---->吞吐量的考虑
	---->存储和读取的流程

主从结构：
	主节点， namenode
	从节点，有很多个: datanode
namenode负责：
	接收用户操作请求
	维护文件系统的目录结构
	管理文件与block之间关系，block与datanode之间关系
datanode负责：
	存储文件
	文件被分成block存储在磁盘上
	为保证数据安全，文件会有多个副本

mapreduce设计思想介绍 
	----主从结构，主节点jobtracker，从节点tasktracker，整个框架如何将任务
		并发化，如何实现容错
	---->用一个海量求和的案例来说明运算的并发化思想：
        a、用一个线程一次性全量求和
	    b、将整个求和任务分成两个步骤，第一个步骤局部求和，这样可以并发进行；
	    第二个步骤必须全局处理，用一个线程来执行，但是它的输入数据集已经很小，不会成为瓶颈

	---->并发思想的编程模型实现了，但是并发协作的机制产生了大量公共管理问题，
	引出mapreduce的资源管理，任务调度，错误重试，并从这里可以引出
	hadoop2.0的yarn的思想及与hadoop1.0的对比
```

